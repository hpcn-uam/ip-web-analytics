{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the limits of privacy and data usage for web browsing analytics\n",
    "## Contact\n",
    "- Daniel Perdices <daniel.perdices at uam.es>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Mvi237kVlU6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "import tensorflow.keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import socket\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import hashing_trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MQfv8SQMSxjs"
   },
   "outputs": [],
   "source": [
    "def ip2int(addr):\n",
    "    return struct.unpack(\"!I\", socket.inet_aton(addr))[0]\n",
    "\n",
    "def str2IP(addr):\n",
    "  addr2 = addr.split(\",\")\n",
    "  if len(addr2) > 1:\n",
    "    addr = addr.replace(\",172.17.0.3\", \"\")\n",
    "  pieces = addr.split(\".\")\n",
    "  if len(pieces) != 4:\n",
    "    print(addr)\n",
    "  return ip2int(addr)\n",
    "\n",
    "def createDocFromFile(filename, sampling_rate=None):\n",
    "  domain = filename.split(\"/\")[-2]\n",
    "  UA = filename.split(\"/\")[-4]\n",
    "  df = pd.read_csv(filename)\n",
    "  #df.serverIP = df.serverIP.apply(str2IP)\n",
    "  dns_server = filename.split(\"/\")[0].replace(\"pcaps_dns_\", \"\").replace(\"_\", \".\")\n",
    "  if sampling_rate is not None:\n",
    "    all_packets = df.totalPackets.sum()\n",
    "    probabilities = df.totalPackets / all_packets\n",
    "    s = all_packets * sampling_rate\n",
    "    selected_indices = set(np.random.choice(df.index, size=s, p=probabilities))\n",
    "    filtered = df.iloc[selected_indices,:]\n",
    "  else:\n",
    "    filtered = df\n",
    "\n",
    "  return {\"words\": filtered.serverIP.values, \"number\": np.uint32(filtered.serverIP.apply(str2IP).values), \"tags\": [domain], \"filename\": filename, \"UA\": UA, \"dns_server\": dns_server}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EEdui68XVzmz"
   },
   "outputs": [],
   "source": [
    "# Defaults\n",
    "vocab_length = 60000\n",
    "max_length = 250\n",
    "def load_dataset(dnss=[\"150.244.9.100\"], vocab_length = vocab_length, max_length=max_length, sampling_rate=None):\n",
    "  # Data should be downloaded before calling this function to load the dataset\n",
    "\n",
    "  # Create corpus (TODO: parallel)\n",
    "  corpus = [createDocFromFile(filename, sampling_rate=sampling_rate) for filename in glob.glob(\"pcaps_dns_*/U*/PartialFootprints/*/*.summary\")]\n",
    "\n",
    "  # Build vector Y\n",
    "  classes = [e[\"tags\"][0] for e in corpus]\n",
    "  s = [e[\"dns_server\"] for e in corpus]\n",
    "\n",
    "  # Build hash encoding\n",
    "  embedded_sentences = [hashing_trick(\" \".join(e[\"words\"]), vocab_length, hash_function=\"md5\") for e in corpus]\n",
    "    \n",
    "  # Build padded sentences\n",
    "  padded_sentences = pad_sequences(embedded_sentences, max_length, padding='post')\n",
    "\n",
    "  return padded_sentences, s, classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and perform train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "R3PXEsI7zV_M",
    "outputId": "83f500f5-3dea-4e30-a123-60f6812e61fe"
   },
   "outputs": [],
   "source": [
    "X, _, classes = load_dataset(dnss=[\"150.244.9.100\", \"1.1.1.1\", \"8.8.8.8\", \"9.9.9.9\", \"208.67.222.222\"], sampling_rate=None)\n",
    "nclasses = np.unique(classes).shape[0]\n",
    "class_encoder = LabelEncoder()\n",
    "class_encoder.fit(sorted(np.unique(classes)))\n",
    "Y = to_categorical(class_encoder.fit_transform(classes))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2, random_state=0)\n",
    "# Validation can be used for hyperparameter searching. Since we already provide hyperparams, it is not used.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, stratify=Y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-NADmf6JyU04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 75)                1575      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               11400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               37750     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 350)               87850     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               140400    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               200500    \n",
      "=================================================================\n",
      "Total params: 1,679,475\n",
      "Trainable params: 1,679,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_length, 20, input_length=max_length))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(75, activation=\"relu\"))\n",
    "model.add(Dense(150, activation=\"relu\"))\n",
    "model.add(Dense(250, activation=\"relu\"))\n",
    "model.add(Dense(350, activation=\"relu\"))\n",
    "model.add(Dense(400, activation=\"relu\"))\n",
    "model.add(Dense(nclasses, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[Accuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uV1mxMIEdKuw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((78306, 250), (19577, 250), (24471, 250)),\n",
       " ((78306, 500), (19577, 500), (24471, 500)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, X_val.shape, X_test.shape), (Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kCEvMiLFfceL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.7972 - accuracy: 0.1461\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 0.9819 - accuracy: 0.1458\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.4194 - accuracy: 0.3839\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 0.7151 - accuracy: 0.3827\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.2938 - accuracy: 0.6049\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 0.7153 - accuracy: 0.6035\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.2498 - accuracy: 0.6944\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 0.7559 - accuracy: 0.6928\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.2234 - accuracy: 0.7443\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 0.8346 - accuracy: 0.7426\n",
      "2448/2448 [==============================] - 6s 3ms/step - loss: 0.2169 - accuracy: 0.7682\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 0.9090 - accuracy: 0.7663\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.1856 - accuracy: 0.8016\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 0.9618 - accuracy: 0.7995\n",
      "2448/2448 [==============================] - 6s 3ms/step - loss: 0.1708 - accuracy: 0.8182\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 1.0160 - accuracy: 0.8163\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.1532 - accuracy: 0.8455\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 1.1539 - accuracy: 0.8434\n",
      "2448/2448 [==============================] - 6s 3ms/step - loss: 0.1278 - accuracy: 0.8604\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 1.1986 - accuracy: 0.8582\n",
      "2448/2448 [==============================] - 6s 3ms/step - loss: 0.1168 - accuracy: 0.8750\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 1.3011 - accuracy: 0.8729\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0945 - accuracy: 0.8911\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 1.4402 - accuracy: 0.8889\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0977 - accuracy: 0.9104\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 1.6749 - accuracy: 0.9085\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.1060 - accuracy: 0.9217\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 1.8531 - accuracy: 0.9203\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0748 - accuracy: 0.9264\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 1.8401 - accuracy: 0.9247\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0544 - accuracy: 0.9331\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 1.8857 - accuracy: 0.9313\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0631 - accuracy: 0.9416\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.0866 - accuracy: 0.9399\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0684 - accuracy: 0.9374\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.0661 - accuracy: 0.9359\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0522 - accuracy: 0.9400\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.1051 - accuracy: 0.9382\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0612 - accuracy: 0.9466\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.1921 - accuracy: 0.9450\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0532 - accuracy: 0.9431\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.2278 - accuracy: 0.9413\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0814 - accuracy: 0.9405\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 2.2471 - accuracy: 0.9391\n",
      "2448/2448 [==============================] - 6s 3ms/step - loss: 0.0491 - accuracy: 0.9448\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.2036 - accuracy: 0.9428\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0551 - accuracy: 0.9429\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 2.2783 - accuracy: 0.9410\n",
      "2448/2448 [==============================] - 6s 3ms/step - loss: 0.0510 - accuracy: 0.9476\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 2.2494 - accuracy: 0.9456\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0638 - accuracy: 0.9461\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.4598 - accuracy: 0.9441\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0480 - accuracy: 0.9443\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.4242 - accuracy: 0.9421\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0599 - accuracy: 0.9423\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.4777 - accuracy: 0.9407\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0437 - accuracy: 0.9505\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.4509 - accuracy: 0.9484\n",
      "2448/2448 [==============================] - 6s 2ms/step - loss: 0.0492 - accuracy: 0.9497\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.4632 - accuracy: 0.9478\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "  history = model.fit(X_train, Y_train, epochs=100, batch_size=1000, verbose=0, validation_data=(X_val, Y_val))\n",
    "  model.evaluate(X_train, Y_train)\n",
    "  model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIz1izGrInJ9"
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepDNS with IPs - all",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
